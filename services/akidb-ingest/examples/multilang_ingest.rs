/// Example: Multi-language vector ingestion with automatic language detection
///
/// This example demonstrates how to use AkiDB's language detection and CJK
/// tokenization features for offline RAG systems supporting multiple languages.
///
/// Usage:
///   cargo run --example multilang_ingest
///
/// Supported Languages:
///   - EN (English)
///   - FR (French)
///   - ZH (Chinese - Simplified & Traditional)
///   - ES (Spanish)
///   - JA (Japanese)
use akidb_ingest::language::{LanguageDetector, SupportedLanguage};
use std::collections::HashMap;

fn main() {
    println!("ğŸŒ AkiDB Multi-Language Ingestion Example\n");

    let detector = LanguageDetector::new();

    // Example texts in different languages
    let examples = vec![
        (
            "English",
            "The quick brown fox jumps over the lazy dog. This is a sample English text.",
        ),
        (
            "French",
            "Le renard brun rapide saute par-dessus le chien paresseux. Ceci est un exemple de texte franÃ§ais.",
        ),
        (
            "Spanish",
            "El rÃ¡pido zorro marrÃ³n salta sobre el perro perezoso. Este es un texto de ejemplo en espaÃ±ol.",
        ),
        (
            "Chinese",
            "æ•æ·çš„æ£•è‰²ç‹ç‹¸è·³è¿‡æ‡’ç‹—ã€‚è¿™æ˜¯ä¸€ä¸ªä¸­æ–‡ç¤ºä¾‹æ–‡æœ¬ã€‚äººå·¥æ™ºèƒ½å’Œæœºå™¨å­¦ä¹ æ­£åœ¨æ”¹å˜ä¸–ç•Œã€‚",
        ),
        (
            "Japanese",
            "ç´ æ—©ã„èŒ¶è‰²ã®ã‚­ãƒ„ãƒãŒæ€ ã‘è€…ã®çŠ¬ã‚’é£›ã³è¶Šãˆã¾ã™ã€‚ã“ã‚Œã¯æ—¥æœ¬èªã®ã‚µãƒ³ãƒ—ãƒ«ãƒ†ã‚­ã‚¹ãƒˆã§ã™ã€‚",
        ),
    ];

    for (label, text) in examples {
        println!("â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€");
        println!("ğŸ“ {label}:");
        println!("   Text: {text}");
        println!();

        // Detect language
        match detector.detect(text) {
            Ok(lang) => {
                println!("   âœ… Detected: {} ({})", lang.name(), lang.code());
                println!("   ğŸ”¤ CJK: {}", if lang.is_cjk() { "Yes" } else { "No" });

                // Get detailed metadata
                if let Ok(metadata) = detector.detect_with_metadata(text) {
                    println!("   ğŸ“Š Confidence: {:.2}%", metadata.confidence * 100.0);
                    println!("   ğŸ”¢ Tokens: {}", metadata.token_count);
                }

                // Tokenize
                if let Ok(tokens) = detector.tokenize(text, lang) {
                    println!(
                        "   ğŸ” First 10 tokens: {:?}",
                        &tokens[..tokens.len().min(10)]
                    );
                }

                // Enrich payload with language metadata
                let mut payload = HashMap::new();
                payload.insert("content".to_string(), serde_json::json!(text));

                if let Ok(enriched) = detector.enrich_payload(text, payload) {
                    println!("   ğŸ“¦ Enriched Payload:");
                    for (key, value) in enriched.iter() {
                        println!("      - {}: {}", key, value);
                    }
                }
            }
            Err(e) => {
                println!("   âŒ Detection failed: {}", e);
            }
        }

        println!();
    }

    // Example: Batch processing with language filtering
    println!("â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€");
    println!("ğŸ“š Batch Processing Example:");
    println!();

    let documents = vec![
        "This is an English document about AI.",
        "Ceci est un document franÃ§ais sur l'IA.",
        "ã“ã‚Œã¯AIã«é–¢ã™ã‚‹æ—¥æœ¬èªã®æ–‡æ›¸ã§ã™ã€‚",
        "Este es un documento espaÃ±ol sobre IA.",
        "è¿™æ˜¯ä¸€ä»½å…³äºäººå·¥æ™ºèƒ½çš„ä¸­æ–‡æ–‡ä»¶ã€‚",
    ];

    let mut language_counts: HashMap<String, usize> = HashMap::new();

    for doc in &documents {
        if let Ok(lang) = detector.detect(doc) {
            *language_counts.entry(lang.code().to_string()).or_insert(0) += 1;
        }
    }

    println!("   ğŸ“Š Language Distribution:");
    for (lang, count) in language_counts {
        println!("      {}: {} documents", lang, count);
    }

    println!();
    println!("âœ… Multi-language ingestion example complete!");
    println!();
    println!("ğŸ’¡ Integration Tips:");
    println!("   1. Use LanguageDetector::detect() for basic language detection");
    println!("   2. Use detect_with_metadata() for detailed analysis");
    println!("   3. Use enrich_payload() to add language metadata to vectors");
    println!("   4. Filter by language in queries using 'language' field");
    println!("   5. For CJK languages, consider integrating:");
    println!("      - Chinese: jieba-rs for better word segmentation");
    println!("      - Japanese: lindera for morphological analysis");
}
